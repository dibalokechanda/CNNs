When convolution operation is discussed, often the batch dimension is ignored for simplicity. One of the reason is during architecture implementation (in code), we almost never have to worry about the batch dimension. That batch dimension is taken care of by the deep learning framework.

![[Pasted image 20240703031342.png]]

Consider the batch size $N$ as shown in the diagram above. This means the input is a not a single feature volume but $N$ feature volumes. Also, output also consists of $N$ feature volume. Because of this the true shape of the input tensor is $N\times C_{in}\times H_{in} \times W_{in}$ and for output tensor  $N\times C_{out}\times H_{out} \times W_{out}$

> When the code for a CNN architecture is written, it is written considering how to handle a single image as input. The batch processing is automatically handled by the deep learning framework.



